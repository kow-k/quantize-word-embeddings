$ python evaluate_quantization.py --use-lebesgue --base-k 8 models-open/glove-wiki-gigaword-100.bin 

================================================================================
QUANTIZATION EVALUATION
Base k: 8 (precision: ~0.2500 per step)
Mode: Lebesgue/equi-depth for skewed dimensions
================================================================================

================================================================================
Processing: models-open/glove-wiki-gigaword-100.bin
================================================================================

  Attempting to load as binary with gensim...
  ✓ Loaded as Word2Vec binary format
================================================================================
QUANTIZATION COMPARISON: glove-wiki-gigaword-100.bin
================================================================================

1. ORIGINAL (No quantization)
--------------------------------------------------------------------------------

Original:
  STS correlation:  0.5589
  SICK correlation: 0.7953
  Analogy accuracy: 33.33%
  Mean unique/dim:  190652.7
  Mean |skewness|:  0.277
  Mean kurtosis:    1.199
  Storage size:     156.4 MB
  Bits per value:   17.54
  Compression:      1.0×

2. UNIFORM QUANTIZATION (k=8)
--------------------------------------------------------------------------------

Uniform k=8:
  STS correlation:  0.4767
  SICK correlation: 0.7691
  Analogy accuracy: 33.33%
  Mean unique/dim:  8.0
  Mean |skewness|:  0.282
  Mean kurtosis:    0.681
  Storage size:     14.3 MB
  Bits per value:   3.00
  Compression:      10.7×

3. ADAPTIVE QUANTIZATION (base_k=8)
--------------------------------------------------------------------------------
Analyzing 100 dimensions...
  Dim 0: other (k=8)
  Dim 20: other (k=8)
  Dim 40: other (k=8)
  Dim 60: other (k=8)
  Dim 80: right_skewed (k=12)

Quantizing 100 dimensions adaptively...
  Dim 0: 196136 → 8 unique values (uniform)
  Dim 20: 187020 → 8 unique values (uniform)
  Dim 40: 187473 → 8 unique values (uniform)
  Dim 60: 194817 → 8 unique values (uniform)
  Dim 80: 173228 → 12 unique values (lebesgue)

======================================================================
ADAPTIVE QUANTIZATION SUMMARY
======================================================================
Total dimensions: 100

Distribution types:
  other               :  87 ( 87.0%)
  right_skewed        :   8 (  8.0%)
  left_skewed         :   5 (  5.0%)

Quantization methods:
  uniform             :  87 ( 87.0%)
  lebesgue            :  13 ( 13.0%)

Quantization levels (k):
  Range: [8, 12]
  Mean: 8.5
  Median: 8.0
======================================================================


Adaptive:
  STS correlation:  0.4952
  SICK correlation: 0.7831
  Analogy accuracy: 33.33%
  Mean unique/dim:  8.5
  Mean |skewness|:  0.276
  Mean kurtosis:    0.532
  Storage size:     14.3 MB
  Bits per value:   3.00
  Compression:      10.7×

================================================================================
COMPARISON TABLE: glove-wiki-gigaword-100.bin
================================================================================
Method                      STS       SICK    Analogy   Size(MB)   Compress
--------------------------------------------------------------------------------
Original                 0.5589     0.7953     33.33%      156.4       1.0×
Uniform                  0.4767     0.7691     33.33%       14.3      10.7×
Adaptive                 0.4952     0.7831     33.33%       14.3      10.7×
--------------------------------------------------------------------------------
Improvements over original:
  Uniform    - STS: -14.7%  SICK: -3.3%  Size: -91% (10.7× compression)
  Adaptive   - STS: -11.4%  SICK: -1.5%  Size: -91% (10.7× compression)
================================================================================

$ python evaluate_quantization.py --use-lebesgue --base-k 16 models-open/glove-wiki-gigaword-100.bin

================================================================================
QUANTIZATION EVALUATION
Base k: 16 (precision: ~0.1250 per step)
Mode: Lebesgue/equi-depth for skewed dimensions
================================================================================

================================================================================
Processing: models-open/glove-wiki-gigaword-100.bin
================================================================================

  Attempting to load as binary with gensim...
  ✓ Loaded as Word2Vec binary format
================================================================================
QUANTIZATION COMPARISON: glove-wiki-gigaword-100.bin
================================================================================

1. ORIGINAL (No quantization)
--------------------------------------------------------------------------------

Original:
  STS correlation:  0.5589
  SICK correlation: 0.7953
  Analogy accuracy: 33.33%
  Mean unique/dim:  190652.7
  Mean |skewness|:  0.277
  Mean kurtosis:    1.199
  Storage size:     156.4 MB
  Bits per value:   17.54
  Compression:      1.0×

2. UNIFORM QUANTIZATION (k=16)
--------------------------------------------------------------------------------

Uniform k=16:
  STS correlation:  0.5564
  SICK correlation: 0.7764
  Analogy accuracy: 33.33%
  Mean unique/dim:  15.9
  Mean |skewness|:  0.252
  Mean kurtosis:    1.047
  Storage size:     18.6 MB
  Bits per value:   3.91
  Compression:      8.2×

3. ADAPTIVE QUANTIZATION (base_k=16)
--------------------------------------------------------------------------------
Analyzing 100 dimensions...
  Dim 0: other (k=16)
  Dim 20: other (k=16)
  Dim 40: other (k=16)
  Dim 60: other (k=16)
  Dim 80: right_skewed (k=24)

Quantizing 100 dimensions adaptively...
  Dim 0: 196136 → 15 unique values (uniform)
  Dim 20: 187020 → 15 unique values (uniform)
  Dim 40: 187473 → 16 unique values (uniform)
  Dim 60: 194817 → 15 unique values (uniform)
  Dim 80: 173228 → 24 unique values (lebesgue)

======================================================================
ADAPTIVE QUANTIZATION SUMMARY
======================================================================
Total dimensions: 100

Distribution types:
  other               :  87 ( 87.0%)
  right_skewed        :   8 (  8.0%)
  left_skewed         :   5 (  5.0%)

Quantization methods:
  uniform             :  87 ( 87.0%)
  lebesgue            :  13 ( 13.0%)

Quantization levels (k):
  Range: [16, 24]
  Mean: 17.0
  Median: 16.0
======================================================================


Adaptive:
  STS correlation:  0.5596
  SICK correlation: 0.7949
  Analogy accuracy: 33.33%
  Mean unique/dim:  16.9
  Mean |skewness|:  0.243
  Mean kurtosis:    0.913
  Storage size:     19.1 MB
  Bits per value:   4.00
  Compression:      8.0×

================================================================================
COMPARISON TABLE: glove-wiki-gigaword-100.bin
================================================================================
Method                      STS       SICK    Analogy   Size(MB)   Compress
--------------------------------------------------------------------------------
Original                 0.5589     0.7953     33.33%      156.4       1.0×
Uniform                  0.5564     0.7764     33.33%       18.6       8.2×
Adaptive                 0.5596     0.7949     33.33%       19.1       8.0×
--------------------------------------------------------------------------------
Improvements over original:
  Uniform    - STS: -0.5%  SICK: -2.4%  Size: -88% (8.2× compression)
  Adaptive   - STS: +0.1%  SICK: -0.1%  Size: -88% (8.0× compression)
================================================================================

$ python evaluate_quantization.py --use-lebesgue --base-k 20 models-open/glove-wiki-gigaword-100.bin

================================================================================
QUANTIZATION EVALUATION
Base k: 20 (precision: ~0.1000 per step)
Mode: Lebesgue/equi-depth for skewed dimensions
================================================================================

================================================================================
Processing: models-open/glove-wiki-gigaword-100.bin
================================================================================

  Attempting to load as binary with gensim...
  ✓ Loaded as Word2Vec binary format
================================================================================
QUANTIZATION COMPARISON: glove-wiki-gigaword-100.bin
================================================================================

1. ORIGINAL (No quantization)
--------------------------------------------------------------------------------

Original:
  STS correlation:  0.5589
  SICK correlation: 0.7953
  Analogy accuracy: 33.33%
  Mean unique/dim:  190652.7
  Mean |skewness|:  0.277
  Mean kurtosis:    1.199
  Storage size:     156.4 MB
  Bits per value:   17.54
  Compression:      1.0×

2. UNIFORM QUANTIZATION (k=20)
--------------------------------------------------------------------------------

Uniform k=20:
  STS correlation:  0.5623
  SICK correlation: 0.8055
  Analogy accuracy: 33.33%
  Mean unique/dim:  19.7
  Mean |skewness|:  0.261
  Mean kurtosis:    1.102
  Storage size:     20.3 MB
  Bits per value:   4.25
  Compression:      7.5×

3. ADAPTIVE QUANTIZATION (base_k=20)
--------------------------------------------------------------------------------
Analyzing 100 dimensions...
  Dim 0: other (k=20)
  Dim 20: other (k=20)
  Dim 40: other (k=20)
  Dim 60: other (k=20)
  Dim 80: right_skewed (k=30)

Quantizing 100 dimensions adaptively...
  Dim 0: 196136 → 18 unique values (uniform)
  Dim 20: 187020 → 19 unique values (uniform)
  Dim 40: 187473 → 19 unique values (uniform)
  Dim 60: 194817 → 18 unique values (uniform)
  Dim 80: 173228 → 30 unique values (lebesgue)

======================================================================
ADAPTIVE QUANTIZATION SUMMARY
======================================================================
Total dimensions: 100

Distribution types:
  other               :  87 ( 87.0%)
  right_skewed        :   8 (  8.0%)
  left_skewed         :   5 (  5.0%)

Quantization methods:
  uniform             :  87 ( 87.0%)
  lebesgue            :  13 ( 13.0%)

Quantization levels (k):
  Range: [20, 30]
  Mean: 21.3
  Median: 20.0
======================================================================


Adaptive:
  STS correlation:  0.5515
  SICK correlation: 0.8264
  Analogy accuracy: 33.33%
  Mean unique/dim:  21.0
  Mean |skewness|:  0.251
  Mean kurtosis:    0.975
  Storage size:     20.6 MB
  Bits per value:   4.32
  Compression:      7.4×

================================================================================
COMPARISON TABLE: glove-wiki-gigaword-100.bin
================================================================================
Method                      STS       SICK    Analogy   Size(MB)   Compress
--------------------------------------------------------------------------------
Original                 0.5589     0.7953     33.33%      156.4       1.0×
Uniform                  0.5623     0.8055     33.33%       20.3       7.5×
Adaptive                 0.5515     0.8264     33.33%       20.6       7.4×
--------------------------------------------------------------------------------
Improvements over original:
  Uniform    - STS: +0.6%  SICK: +1.3%  Size: -87% (7.5× compression)
  Adaptive   - STS: -1.3%  SICK: +3.9%  Size: -87% (7.4× compression)
================================================================================

$ python evaluate_quantization.py --use-lebesgue --base-k 25 models-open/glove-wiki-gigaword-100.bin

================================================================================
QUANTIZATION EVALUATION
Base k: 25 (precision: ~0.0800 per step)
Mode: Lebesgue/equi-depth for skewed dimensions
================================================================================

================================================================================
Processing: models-open/glove-wiki-gigaword-100.bin
================================================================================

  Attempting to load as binary with gensim...
  ✓ Loaded as Word2Vec binary format
================================================================================
QUANTIZATION COMPARISON: glove-wiki-gigaword-100.bin
================================================================================

1. ORIGINAL (No quantization)
--------------------------------------------------------------------------------

Original:
  STS correlation:  0.5589
  SICK correlation: 0.7953
  Analogy accuracy: 33.33%
  Mean unique/dim:  190652.7
  Mean |skewness|:  0.277
  Mean kurtosis:    1.199
  Storage size:     156.4 MB
  Bits per value:   17.54
  Compression:      1.0×

2. UNIFORM QUANTIZATION (k=25)
--------------------------------------------------------------------------------

Uniform k=25:
  STS correlation:  0.5472
  SICK correlation: 0.7935
  Analogy accuracy: 33.33%
  Mean unique/dim:  24.5
  Mean |skewness|:  0.267
  Mean kurtosis:    1.137
  Storage size:     21.9 MB
  Bits per value:   4.58
  Compression:      7.0×

3. ADAPTIVE QUANTIZATION (base_k=25)
--------------------------------------------------------------------------------
Analyzing 100 dimensions...
  Dim 0: other (k=25)
  Dim 20: other (k=25)
  Dim 40: other (k=25)
  Dim 60: other (k=25)
  Dim 80: right_skewed (k=37)

Quantizing 100 dimensions adaptively...
  Dim 0: 196136 → 22 unique values (uniform)
  Dim 20: 187020 → 23 unique values (uniform)
  Dim 40: 187473 → 24 unique values (uniform)
  Dim 60: 194817 → 22 unique values (uniform)
  Dim 80: 173228 → 37 unique values (lebesgue)

======================================================================
ADAPTIVE QUANTIZATION SUMMARY
======================================================================
Total dimensions: 100

Distribution types:
  other               :  87 ( 87.0%)
  right_skewed        :   8 (  8.0%)
  left_skewed         :   5 (  5.0%)

Quantization methods:
  uniform             :  87 ( 87.0%)
  lebesgue            :  13 ( 13.0%)

Quantization levels (k):
  Range: [25, 37]
  Mean: 26.6
  Median: 25.0
======================================================================


Adaptive:
  STS correlation:  0.5435
  SICK correlation: 0.8081
  Analogy accuracy: 33.33%
  Mean unique/dim:  26.0
  Mean |skewness|:  0.258
  Mean kurtosis:    1.020
  Storage size:     22.4 MB
  Bits per value:   4.70
  Compression:      6.8×

================================================================================
COMPARISON TABLE: glove-wiki-gigaword-100.bin
================================================================================
Method                      STS       SICK    Analogy   Size(MB)   Compress
--------------------------------------------------------------------------------
Original                 0.5589     0.7953     33.33%      156.4       1.0×
Uniform                  0.5472     0.7935     33.33%       21.9       7.0×
Adaptive                 0.5435     0.8081     33.33%       22.4       6.8×
--------------------------------------------------------------------------------
Improvements over original:
  Uniform    - STS: -2.1%  SICK: -0.2%  Size: -86% (7.0× compression)
  Adaptive   - STS: -2.8%  SICK: +1.6%  Size: -86% (6.8× compression)
================================================================================

$ python evaluate_quantization.py --use-lebesgue --base-k 32 models-open/glove-wiki-gigaword-100.bin

================================================================================
QUANTIZATION EVALUATION
Base k: 32 (precision: ~0.0625 per step)
Mode: Lebesgue/equi-depth for skewed dimensions
================================================================================

================================================================================
Processing: models-open/glove-wiki-gigaword-100.bin
================================================================================

  Attempting to load as binary with gensim...
  ✓ Loaded as Word2Vec binary format
================================================================================
QUANTIZATION COMPARISON: glove-wiki-gigaword-100.bin
================================================================================

1. ORIGINAL (No quantization)
--------------------------------------------------------------------------------

Original:
  STS correlation:  0.5589
  SICK correlation: 0.7953
  Analogy accuracy: 33.33%
  Mean unique/dim:  190652.7
  Mean |skewness|:  0.277
  Mean kurtosis:    1.199
  Storage size:     156.4 MB
  Bits per value:   17.54
  Compression:      1.0×

2. UNIFORM QUANTIZATION (k=32)
--------------------------------------------------------------------------------

Uniform k=32:
  STS correlation:  0.5565
  SICK correlation: 0.7827
  Analogy accuracy: 33.33%
  Mean unique/dim:  30.9
  Mean |skewness|:  0.271
  Mean kurtosis:    1.162
  Storage size:     23.4 MB
  Bits per value:   4.91
  Compression:      6.5×

3. ADAPTIVE QUANTIZATION (base_k=32)
--------------------------------------------------------------------------------
Analyzing 100 dimensions...
  Dim 0: other (k=32)
  Dim 20: other (k=32)
  Dim 40: other (k=32)
  Dim 60: other (k=32)
  Dim 80: right_skewed (k=48)

Quantizing 100 dimensions adaptively...
  Dim 0: 196136 → 27 unique values (uniform)
  Dim 20: 187020 → 29 unique values (uniform)
  Dim 40: 187473 → 30 unique values (uniform)
  Dim 60: 194817 → 28 unique values (uniform)
  Dim 80: 173228 → 48 unique values (lebesgue)

======================================================================
ADAPTIVE QUANTIZATION SUMMARY
======================================================================
Total dimensions: 100

Distribution types:
  other               :  87 ( 87.0%)
  right_skewed        :   8 (  8.0%)
  left_skewed         :   5 (  5.0%)

Quantization methods:
  uniform             :  87 ( 87.0%)
  lebesgue            :  13 ( 13.0%)

Quantization levels (k):
  Range: [32, 48]
  Mean: 34.1
  Median: 32.0
======================================================================


Adaptive:
  STS correlation:  0.5546
  SICK correlation: 0.8011
  Analogy accuracy: 33.33%
  Mean unique/dim:  33.1
  Mean |skewness|:  0.263
  Mean kurtosis:    1.058
  Storage size:     24.1 MB
  Bits per value:   5.04
  Compression:      6.3×

================================================================================
COMPARISON TABLE: glove-wiki-gigaword-100.bin
================================================================================
Method                      STS       SICK    Analogy   Size(MB)   Compress
--------------------------------------------------------------------------------
Original                 0.5589     0.7953     33.33%      156.4       1.0×
Uniform                  0.5565     0.7827     33.33%       23.4       6.5×
Adaptive                 0.5546     0.8011     33.33%       24.1       6.3×
--------------------------------------------------------------------------------
Improvements over original:
  Uniform    - STS: -0.4%  SICK: -1.6%  Size: -85% (6.5× compression)
  Adaptive   - STS: -0.8%  SICK: +0.7%  Size: -85% (6.3× compression)
================================================================================

$ python evaluate_quantization.py --use-lebesgue --base-k 33 models-open/glove-wiki-gigaword-100.bin

================================================================================
QUANTIZATION EVALUATION
Base k: 33 (precision: ~0.0606 per step)
Mode: Lebesgue/equi-depth for skewed dimensions
================================================================================

================================================================================
Processing: models-open/glove-wiki-gigaword-100.bin
================================================================================

  Attempting to load as binary with gensim...
  ✓ Loaded as Word2Vec binary format
================================================================================
QUANTIZATION COMPARISON: glove-wiki-gigaword-100.bin
================================================================================

1. ORIGINAL (No quantization)
--------------------------------------------------------------------------------

Original:
  STS correlation:  0.5589
  SICK correlation: 0.7953
  Analogy accuracy: 33.33%
  Mean unique/dim:  190652.7
  Mean |skewness|:  0.277
  Mean kurtosis:    1.199
  Storage size:     156.4 MB
  Bits per value:   17.54
  Compression:      1.0×

2. UNIFORM QUANTIZATION (k=33)
--------------------------------------------------------------------------------

Uniform k=33:
  STS correlation:  0.5353
  SICK correlation: 0.8062
  Analogy accuracy: 33.33%
  Mean unique/dim:  31.8
  Mean |skewness|:  0.271
  Mean kurtosis:    1.164
  Storage size:     23.6 MB
  Bits per value:   4.95
  Compression:      6.5×

3. ADAPTIVE QUANTIZATION (base_k=33)
--------------------------------------------------------------------------------
Analyzing 100 dimensions...
  Dim 0: other (k=33)
  Dim 20: other (k=33)
  Dim 40: other (k=33)
  Dim 60: other (k=33)
  Dim 80: right_skewed (k=49)

Quantizing 100 dimensions adaptively...
  Dim 0: 196136 → 28 unique values (uniform)
  Dim 20: 187020 → 30 unique values (uniform)
  Dim 40: 187473 → 31 unique values (uniform)
  Dim 60: 194817 → 29 unique values (uniform)
  Dim 80: 173228 → 49 unique values (lebesgue)

======================================================================
ADAPTIVE QUANTIZATION SUMMARY
======================================================================
Total dimensions: 100

Distribution types:
  other               :  87 ( 87.0%)
  right_skewed        :   8 (  8.0%)
  left_skewed         :   5 (  5.0%)

Quantization methods:
  uniform             :  87 ( 87.0%)
  lebesgue            :  13 ( 13.0%)

Quantization levels (k):
  Range: [33, 49]
  Mean: 35.1
  Median: 33.0
======================================================================


Adaptive:
  STS correlation:  0.5486
  SICK correlation: 0.8062
  Analogy accuracy: 33.33%
  Mean unique/dim:  34.0
  Mean |skewness|:  0.263
  Mean kurtosis:    1.061
  Storage size:     24.1 MB
  Bits per value:   5.04
  Compression:      6.3×

================================================================================
COMPARISON TABLE: glove-wiki-gigaword-100.bin
================================================================================
Method                      STS       SICK    Analogy   Size(MB)   Compress
--------------------------------------------------------------------------------
Original                 0.5589     0.7953     33.33%      156.4       1.0×
Uniform                  0.5353     0.8062     33.33%       23.6       6.5×
Adaptive                 0.5486     0.8062     33.33%       24.1       6.3×
--------------------------------------------------------------------------------
Improvements over original:
  Uniform    - STS: -4.2%  SICK: +1.4%  Size: -85% (6.5× compression)
  Adaptive   - STS: -1.8%  SICK: +1.4%  Size: -85% (6.3× compression)
================================================================================

$ python evaluate_quantization.py --use-lebesgue --base-k 50 models-open/glove-wiki-gigaword-100.bin

================================================================================
QUANTIZATION EVALUATION
Base k: 50 (precision: ~0.0400 per step)
Mode: Lebesgue/equi-depth for skewed dimensions
================================================================================

================================================================================
Processing: models-open/glove-wiki-gigaword-100.bin
================================================================================

  Attempting to load as binary with gensim...
  ✓ Loaded as Word2Vec binary format
================================================================================
QUANTIZATION COMPARISON: glove-wiki-gigaword-100.bin
================================================================================

1. ORIGINAL (No quantization)
--------------------------------------------------------------------------------

Original:
  STS correlation:  0.5589
  SICK correlation: 0.7953
  Analogy accuracy: 33.33%
  Mean unique/dim:  190652.7
  Mean |skewness|:  0.277
  Mean kurtosis:    1.199
  Storage size:     156.4 MB
  Bits per value:   17.54
  Compression:      1.0×

2. UNIFORM QUANTIZATION (k=50)
--------------------------------------------------------------------------------

Uniform k=50:
  STS correlation:  0.5583
  SICK correlation: 0.7959
  Analogy accuracy: 33.33%
  Mean unique/dim:  47.2
  Mean |skewness|:  0.275
  Mean kurtosis:    1.184
  Storage size:     26.5 MB
  Bits per value:   5.55
  Compression:      5.8×

3. ADAPTIVE QUANTIZATION (base_k=50)
--------------------------------------------------------------------------------
Analyzing 100 dimensions...
  Dim 0: other (k=50)
  Dim 20: other (k=50)
  Dim 40: other (k=50)
  Dim 60: other (k=50)
  Dim 80: right_skewed (k=75)

Quantizing 100 dimensions adaptively...
  Dim 0: 196136 → 41 unique values (uniform)
  Dim 20: 187020 → 44 unique values (uniform)
  Dim 40: 187473 → 47 unique values (uniform)
  Dim 60: 194817 → 41 unique values (uniform)
  Dim 80: 173228 → 75 unique values (lebesgue)

======================================================================
ADAPTIVE QUANTIZATION SUMMARY
======================================================================
Total dimensions: 100

Distribution types:
  other               :  87 ( 87.0%)
  right_skewed        :   8 (  8.0%)
  left_skewed         :   5 (  5.0%)

Quantization methods:
  uniform             :  87 ( 87.0%)
  lebesgue            :  13 ( 13.0%)

Quantization levels (k):
  Range: [50, 75]
  Mean: 53.2
  Median: 50.0
======================================================================


Adaptive:
  STS correlation:  0.5543
  SICK correlation: 0.8048
  Analogy accuracy: 33.33%
  Mean unique/dim:  50.7
  Mean |skewness|:  0.268
  Mean kurtosis:    1.103
  Storage size:     26.9 MB
  Bits per value:   5.64
  Compression:      5.7×

================================================================================
COMPARISON TABLE: glove-wiki-gigaword-100.bin
================================================================================
Method                      STS       SICK    Analogy   Size(MB)   Compress
--------------------------------------------------------------------------------
Original                 0.5589     0.7953     33.33%      156.4       1.0×
Uniform                  0.5583     0.7959     33.33%       26.5       5.8×
Adaptive                 0.5543     0.8048     33.33%       26.9       5.7×
--------------------------------------------------------------------------------
Improvements over original:
  Uniform    - STS: -0.1%  SICK: +0.1%  Size: -83% (5.8× compression)
  Adaptive   - STS: -0.8%  SICK: +1.2%  Size: -83% (5.7× compression)
================================================================================

$ python evaluate_quantization.py --use-lebesgue --base-k 64 models-open/glove-wiki-gigaword-100.bin 

================================================================================
QUANTIZATION EVALUATION
Base k: 64 (precision: ~0.0312 per step)
Mode: Lebesgue/equi-depth for skewed dimensions
================================================================================

================================================================================
Processing: models-open/glove-wiki-gigaword-100.bin
================================================================================

  Attempting to load as binary with gensim...
  ✓ Loaded as Word2Vec binary format
================================================================================
QUANTIZATION COMPARISON: glove-wiki-gigaword-100.bin
================================================================================

1. ORIGINAL (No quantization)
--------------------------------------------------------------------------------

Original:
  STS correlation:  0.5589
  SICK correlation: 0.7953
  Analogy accuracy: 33.33%
  Mean unique/dim:  190652.7
  Mean |skewness|:  0.277
  Mean kurtosis:    1.199
  Storage size:     156.4 MB
  Bits per value:   17.54
  Compression:      1.0×

2. UNIFORM QUANTIZATION (k=64)
--------------------------------------------------------------------------------

Uniform k=64:
  STS correlation:  0.5571
  SICK correlation: 0.8000
  Analogy accuracy: 33.33%
  Mean unique/dim:  59.5
  Mean |skewness|:  0.276
  Mean kurtosis:    1.190
  Storage size:     28.1 MB
  Bits per value:   5.88
  Compression:      5.4×

3. ADAPTIVE QUANTIZATION (base_k=64)
--------------------------------------------------------------------------------
Analyzing 100 dimensions...
  Dim 0: other (k=64)
  Dim 20: other (k=64)
  Dim 40: other (k=64)
  Dim 60: other (k=64)
  Dim 80: right_skewed (k=96)

Quantizing 100 dimensions adaptively...
  Dim 0: 196136 → 51 unique values (uniform)
  Dim 20: 187020 → 55 unique values (uniform)
  Dim 40: 187473 → 60 unique values (uniform)
  Dim 60: 194817 → 52 unique values (uniform)
  Dim 80: 173228 → 96 unique values (lebesgue)

======================================================================
ADAPTIVE QUANTIZATION SUMMARY
======================================================================
Total dimensions: 100

Distribution types:
  other               :  87 ( 87.0%)
  right_skewed        :   8 (  8.0%)
  left_skewed         :   5 (  5.0%)

Quantization methods:
  uniform             :  87 ( 87.0%)
  lebesgue            :  13 ( 13.0%)

Quantization levels (k):
  Range: [64, 96]
  Mean: 68.2
  Median: 64.0
======================================================================


Adaptive:
  STS correlation:  0.5468
  SICK correlation: 0.8055
  Analogy accuracy: 33.33%
  Mean unique/dim:  64.1
  Mean |skewness|:  0.270
  Mean kurtosis:    1.119
  Storage size:     28.6 MB
  Bits per value:   6.00
  Compression:      5.3×

================================================================================
COMPARISON TABLE: glove-wiki-gigaword-100.bin
================================================================================
Method                      STS       SICK    Analogy   Size(MB)   Compress
--------------------------------------------------------------------------------
Original                 0.5589     0.7953     33.33%      156.4       1.0×
Uniform                  0.5571     0.8000     33.33%       28.1       5.4×
Adaptive                 0.5468     0.8055     33.33%       28.6       5.3×
--------------------------------------------------------------------------------
Improvements over original:
  Uniform    - STS: -0.3%  SICK: +0.6%  Size: -82% (5.4× compression)
  Adaptive   - STS: -2.2%  SICK: +1.3%  Size: -82% (5.3× compression)
================================================================================

$ python evaluate_quantization.py --use-lebesgue --base-k 100 models-open/glove-wiki-gigaword-100.bin

================================================================================
QUANTIZATION EVALUATION
Base k: 100 (precision: ~0.0200 per step)
Mode: Lebesgue/equi-depth for skewed dimensions
================================================================================

================================================================================
Processing: models-open/glove-wiki-gigaword-100.bin
================================================================================

  Attempting to load as binary with gensim...
  ✓ Loaded as Word2Vec binary format
================================================================================
QUANTIZATION COMPARISON: glove-wiki-gigaword-100.bin
================================================================================

1. ORIGINAL (No quantization)
--------------------------------------------------------------------------------

Original:
  STS correlation:  0.5589
  SICK correlation: 0.7953
  Analogy accuracy: 33.33%
  Mean unique/dim:  190652.7
  Mean |skewness|:  0.277
  Mean kurtosis:    1.199
  Storage size:     156.4 MB
  Bits per value:   17.54
  Compression:      1.0×

2. UNIFORM QUANTIZATION (k=100)
--------------------------------------------------------------------------------

Uniform k=100:
  STS correlation:  0.5535
  SICK correlation: 0.7923
  Analogy accuracy: 33.33%
  Mean unique/dim:  90.2
  Mean |skewness|:  0.276
  Mean kurtosis:    1.196
  Storage size:     31.0 MB
  Bits per value:   6.49
  Compression:      4.9×

3. ADAPTIVE QUANTIZATION (base_k=100)
--------------------------------------------------------------------------------
Analyzing 100 dimensions...
  Dim 0: other (k=100)
  Dim 20: other (k=100)
  Dim 40: other (k=100)
  Dim 60: other (k=100)
  Dim 80: right_skewed (k=150)

Quantizing 100 dimensions adaptively...
  Dim 0: 196136 → 75 unique values (uniform)
  Dim 20: 187020 → 85 unique values (uniform)
  Dim 40: 187473 → 92 unique values (uniform)
  Dim 60: 194817 → 80 unique values (uniform)
  Dim 80: 173228 → 150 unique values (lebesgue)

======================================================================
ADAPTIVE QUANTIZATION SUMMARY
======================================================================
Total dimensions: 100

Distribution types:
  other               :  87 ( 87.0%)
  right_skewed        :   8 (  8.0%)
  left_skewed         :   5 (  5.0%)

Quantization methods:
  uniform             :  87 ( 87.0%)
  lebesgue            :  13 ( 13.0%)

Quantization levels (k):
  Range: [100, 150]
  Mean: 106.5
  Median: 100.0
======================================================================


Adaptive:
  STS correlation:  0.5523
  SICK correlation: 0.8024
  Analogy accuracy: 33.33%
  Mean unique/dim:  97.7
  Mean |skewness|:  0.273
  Mean kurtosis:    1.142
  Storage size:     31.5 MB
  Bits per value:   6.60
  Compression:      4.8×

================================================================================
COMPARISON TABLE: glove-wiki-gigaword-100.bin
================================================================================
Method                      STS       SICK    Analogy   Size(MB)   Compress
--------------------------------------------------------------------------------
Original                 0.5589     0.7953     33.33%      156.4       1.0×
Uniform                  0.5535     0.7923     33.33%       31.0       4.9×
Adaptive                 0.5523     0.8024     33.33%       31.5       4.8×
--------------------------------------------------------------------------------
Improvements over original:
  Uniform    - STS: -1.0%  SICK: -0.4%  Size: -80% (4.9× compression)
  Adaptive   - STS: -1.2%  SICK: +0.9%  Size: -80% (4.8× compression)
================================================================================

$ python evaluate_quantization.py --use-lebesgue --base-k 128 models-open/glove-wiki-gigaword-100.bin

================================================================================
QUANTIZATION EVALUATION
Base k: 128 (precision: ~0.0156 per step)
Mode: Lebesgue/equi-depth for skewed dimensions
================================================================================

================================================================================
Processing: models-open/glove-wiki-gigaword-100.bin
================================================================================

  Attempting to load as binary with gensim...
  ✓ Loaded as Word2Vec binary format
================================================================================
QUANTIZATION COMPARISON: glove-wiki-gigaword-100.bin
================================================================================

1. ORIGINAL (No quantization)
--------------------------------------------------------------------------------

Original:
  STS correlation:  0.5589
  SICK correlation: 0.7953
  Analogy accuracy: 33.33%
  Mean unique/dim:  190652.7
  Mean |skewness|:  0.277
  Mean kurtosis:    1.199
  Storage size:     156.4 MB
  Bits per value:   17.54
  Compression:      1.0×

2. UNIFORM QUANTIZATION (k=128)
--------------------------------------------------------------------------------

Uniform k=128:
  STS correlation:  0.5526
  SICK correlation: 0.7989
  Analogy accuracy: 33.33%
  Mean unique/dim:  113.7
  Mean |skewness|:  0.277
  Mean kurtosis:    1.197
  Storage size:     32.6 MB
  Bits per value:   6.82
  Compression:      4.7×

3. ADAPTIVE QUANTIZATION (base_k=128)
--------------------------------------------------------------------------------
Analyzing 100 dimensions...
  Dim 0: other (k=128)
  Dim 20: other (k=128)
  Dim 40: other (k=128)
  Dim 60: other (k=128)
  Dim 80: right_skewed (k=192)

Quantizing 100 dimensions adaptively...
  Dim 0: 196136 → 92 unique values (uniform)
  Dim 20: 187020 → 106 unique values (uniform)
  Dim 40: 187473 → 116 unique values (uniform)
  Dim 60: 194817 → 99 unique values (uniform)
  Dim 80: 173228 → 192 unique values (lebesgue)

======================================================================
ADAPTIVE QUANTIZATION SUMMARY
======================================================================
Total dimensions: 100

Distribution types:
  other               :  87 ( 87.0%)
  right_skewed        :   8 (  8.0%)
  left_skewed         :   5 (  5.0%)

Quantization methods:
  uniform             :  87 ( 87.0%)
  lebesgue            :  13 ( 13.0%)

Quantization levels (k):
  Range: [128, 192]
  Mean: 136.3
  Median: 128.0
======================================================================


Adaptive:
  STS correlation:  0.5520
  SICK correlation: 0.8006
  Analogy accuracy: 33.33%
  Mean unique/dim:  123.5
  Mean |skewness|:  0.274
  Mean kurtosis:    1.151
  Storage size:     33.2 MB
  Bits per value:   6.94
  Compression:      4.6×

================================================================================
COMPARISON TABLE: glove-wiki-gigaword-100.bin
================================================================================
Method                      STS       SICK    Analogy   Size(MB)   Compress
--------------------------------------------------------------------------------
Original                 0.5589     0.7953     33.33%      156.4       1.0×
Uniform                  0.5526     0.7989     33.33%       32.6       4.7×
Adaptive                 0.5520     0.8006     33.33%       33.2       4.6×
--------------------------------------------------------------------------------
Improvements over original:
  Uniform    - STS: -1.1%  SICK: +0.4%  Size: -79% (4.7× compression)
  Adaptive   - STS: -1.2%  SICK: +0.7%  Size: -79% (4.6× compression)
================================================================================